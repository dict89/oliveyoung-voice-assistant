"""
ì˜¬ë¦¬ë¸Œì˜ ìŒì„± ì‡¼í•‘ ì–´ì‹œìŠ¤í„´íŠ¸ ë´‡
Pipecatì„ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ ìŒì„± ëŒ€í™” êµ¬í˜„ (Daily.co Transport)
"""
import asyncio
import os
import sys

from pipecat.audio.vad.silero import SileroVADAnalyzer
from pipecat.audio.vad.vad_analyzer import VADParams
from pipecat.frames.frames import (
    EndFrame,
    TranscriptionFrame,
    TextFrame,
    Frame,
)
from pipecat.pipeline.pipeline import Pipeline
from pipecat.pipeline.runner import PipelineRunner
from pipecat.pipeline.task import PipelineParams, PipelineTask
from pipecat.processors.aggregators.llm_response import (
    LLMAssistantResponseAggregator,
    LLMUserResponseAggregator,
)
from pipecat.processors.frame_processor import FrameDirection, FrameProcessor
from pipecat.services.cartesia.tts import CartesiaTTSService
from pipecat.services.openai.llm import OpenAILLMService
from pipecat.services.openai.stt import OpenAISTTService
from pipecat.transports.daily.transport import DailyParams, DailyTransport

from loguru import logger
from dotenv import load_dotenv

from .store_service import StoreService
from .websocket_manager import broadcast_message

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê±° ì„¤ì •
logger.remove(0)
logger.add(sys.stderr, level="INFO")


class IntentDetectionFilter(FrameProcessor):
    """í•˜ì´ë¸Œë¦¬ë“œ ì˜ë„ íŒë‹¨ í•„í„°: ë¹ ë¥¸ í‚¤ì›Œë“œ ì²´í¬ + LLM ë°±ì—…"""
    
    # í™•ì‹¤í•œ YES í‚¤ì›Œë“œ (ì¦‰ì‹œ í†µê³¼)
    DEFINITE_YES_KEYWORDS = [
        "ì•ˆë…•", "ì¶”ì²œ", "ì•Œë ¤", "ì°¾ì•„", "ë„ì™€", "ì§ˆë¬¸", "ë¬¸ì˜",
        "ì–´ë””", "ìœ„ì¹˜", "ë§¤ì¥", "ì œí’ˆ", "ì˜ì—…", "ì‹œê°„", "ì—°ë½",
        "hello", "hi", "hey", "help", "recommend", "where", "store",
        "product", "location", "contact", "popular", "ì¸ê¸°"
    ]
    
    # í™•ì‹¤í•œ NO íŒ¨í„´ (ì¦‰ì‹œ ì°¨ë‹¨)
    DEFINITE_NO_PATTERNS = [
        "mbc ë‰´ìŠ¤", "kbs", "sbs", "ìë§‰", "êµ¬ë…", "ì¢‹ì•„ìš”",
        "ì‹œì²­", "ê°ì‚¬í•©ë‹ˆë‹¤", "ìˆ˜ê³ ", "ì˜ ë¨¹ê² ìŠµë‹ˆë‹¤"
    ]
    
    def __init__(self, openai_api_key: str):
        super().__init__()
        self.openai_api_key = openai_api_key
        
        # íŒë‹¨ìš© LLM (ë¶ˆëª…í™•í•œ ê²½ìš°ë§Œ ì‚¬ìš©)
        from openai import AsyncOpenAI
        self.client = AsyncOpenAI(api_key=openai_api_key)
        
        self.intent_prompt = """You are an intent classifier for an AI shopping assistant.

Respond with ONLY one word: "YES" or "NO"

YES = User is talking to the AI assistant (asking questions, requesting help)
NO = User is having a side conversation or not addressing the assistant

User input: "{text}"

Your answer (YES or NO):"""
    
    def _quick_keyword_check(self, text: str) -> str:
        """ë¹ ë¥¸ í‚¤ì›Œë“œ ì²´í¬ (ë°€ë¦¬ì´ˆ ë‹¨ìœ„)
        
        Returns:
            "YES" - í™•ì‹¤íˆ AIì—ê²Œ í•˜ëŠ” ë§
            "NO" - í™•ì‹¤íˆ AIì—ê²Œ í•˜ëŠ” ë§ì´ ì•„ë‹˜
            "UNCLEAR" - ë¶ˆëª…í™•, LLM íŒë‹¨ í•„ìš”
        """
        text_lower = text.lower()
        
        # 1. í™•ì‹¤í•œ NO íŒ¨í„´ ì²´í¬ (ê°€ì¥ ë¨¼ì €)
        for pattern in self.DEFINITE_NO_PATTERNS:
            if pattern in text_lower:
                return "NO"
        
        # 2. í™•ì‹¤í•œ YES í‚¤ì›Œë“œ ì²´í¬
        for keyword in self.DEFINITE_YES_KEYWORDS:
            if keyword in text_lower:
                return "YES"
        
        # 3. ë§¤ìš° ì§§ì€ ë¬¸ì¥ì€ ë³´í†µ AIì—ê²Œ í•˜ëŠ” ë§ì´ ì•„ë‹˜
        if len(text.strip()) < 5:
            return "NO"
        
        # 4. ë¶ˆëª…í™•í•œ ê²½ìš° (LLM í•„ìš”)
        return "UNCLEAR"
    
    async def _check_intent_with_llm(self, text: str) -> bool:
        """LLMìœ¼ë¡œ ì˜ë„ íŒë‹¨ (ë¶ˆëª…í™•í•œ ê²½ìš°ë§Œ í˜¸ì¶œ)"""
        try:
            response = await self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "user", "content": self.intent_prompt.format(text=text)}
                ],
                temperature=0,
                max_tokens=5
            )
            
            answer = response.choices[0].message.content.strip().upper()
            return answer == "YES"
            
        except Exception as e:
            logger.error(f"âŒ Intent detection error: {e}")
            return True  # ì˜¤ë¥˜ ì‹œ í†µê³¼
    
    async def process_frame(self, frame: Frame, direction: FrameDirection):
        await super().process_frame(frame, direction)
        
        # TranscriptionFrameë§Œ í•„í„°ë§
        if isinstance(frame, TranscriptionFrame):
            text = frame.text
            
            if text and text.strip() and len(text.strip()) > 1:
                # Step 1: ë¹ ë¥¸ í‚¤ì›Œë“œ ì²´í¬ (ë°€ë¦¬ì´ˆ)
                quick_result = self._quick_keyword_check(text)
                
                if quick_result == "YES":
                    logger.info(f"âœ… [KEYWORD: YES] Fast pass: {text}")
                    await self.push_frame(frame, direction)
                    return
                elif quick_result == "NO":
                    logger.info(f"â­ï¸ [KEYWORD: NO] Fast reject: {text}")
                    return
                else:
                    # Step 2: ë¶ˆëª…í™•í•œ ê²½ìš°ë§Œ LLM ì‚¬ìš©
                    logger.info(f"ğŸ¤” [UNCLEAR] Checking with LLM: {text}")
                    should_respond = await self._check_intent_with_llm(text)
                    
                    if should_respond:
                        logger.info(f"âœ… [LLM: YES] Forwarding to LLM: {text}")
                        await self.push_frame(frame, direction)
                    else:
                        logger.info(f"â­ï¸ [LLM: NO] Ignoring: {text}")
            else:
                return
        else:
            # ë‹¤ë¥¸ í”„ë ˆì„ì€ ê·¸ëŒ€ë¡œ ì „ë‹¬
            await self.push_frame(frame, direction)


class TranscriptLogger(FrameProcessor):
    """ëŒ€í™” ë‚´ìš©ì„ WebSocketìœ¼ë¡œ ì „ì†¡í•˜ëŠ” í”„ë¡œì„¸ì„œ (Intent:YESë§Œ ë„ë‹¬)"""
    
    def __init__(self):
        super().__init__()
        # StoreService ì¸ìŠ¤í„´ìŠ¤ (ì œí’ˆ/ë§¤ì¥ ì •ë³´ ì¡°íšŒìš©)
        from .store_service import StoreService
        self.store_service = StoreService()
    
    async def process_frame(self, frame: Frame, direction: FrameDirection):
        await super().process_frame(frame, direction)
        
        # STT ê²°ê³¼ (ì‚¬ìš©ì ìŒì„± ì¸ì‹) - Intent:YESì¸ ê²ƒë§Œ ì—¬ê¸° ë„ë‹¬
        if isinstance(frame, TranscriptionFrame):
            text = frame.text
            # ë¹ˆ ë¬¸ìì—´ì´ë‚˜ ê³µë°±ë§Œ ìˆëŠ” ê²½ìš° ë¬´ì‹œ
            if text and text.strip() and len(text.strip()) > 1:
                # ë¸Œë¼ìš°ì € ì±„íŒ…ì°½ìœ¼ë¡œë§Œ ì „ì†¡ (ë¡œê·¸ëŠ” IntentDetectionFilterì—ì„œ ì´ë¯¸ ì¶œë ¥)
                await broadcast_message({
                    "type": "transcript",
                    "speaker": "user",
                    "text": text.strip()  # ê³µë°± ì œê±°
                })
        
        # LLM ì‘ë‹µ í…ìŠ¤íŠ¸
        elif isinstance(frame, TextFrame):
            text = frame.text
            if text and text.strip():
                logger.info(f"ğŸ¤– [ASSISTANT]: {text}")
                
                # [PRODUCTS:...] íŒ¨í„´ íŒŒì‹±
                import re
                products_match = re.search(r'\[PRODUCTS:(.*?)\]', text)
                if products_match:
                    product_ids = [pid.strip() for pid in products_match.group(1).split(',')]
                    logger.info(f"ğŸ›ï¸ Found product IDs: {product_ids}")
                    
                    # ì œí’ˆ ì •ë³´ ì¡°íšŒ
                    all_products = self.store_service.get_all_products()
                    selected_products = [
                        p for p in all_products 
                        if p.get('product_id') in product_ids
                    ]
                    
                    if selected_products:
                        # ì´ë¯¸ì§€ í‘œì‹œ ë©”ì‹œì§€ ì „ì†¡
                        await broadcast_message({
                            "type": "show_images",
                            "content_type": "products",
                            "data": {"products": selected_products}
                        })
                        logger.info(f"âœ… Sent product images: {len(selected_products)} items")
                    
                    # í…ìŠ¤íŠ¸ì—ì„œ íƒœê·¸ ì œê±° (TTSìš©)
                    text = re.sub(r'\[PRODUCTS:.*?\]', '', text).strip()
                
                # [STORE:...] íŒ¨í„´ íŒŒì‹±
                store_match = re.search(r'\[STORE:(.*?)\]', text)
                if store_match:
                    store_id = store_match.group(1).strip()
                    logger.info(f"ğŸª Found store ID: {store_id}")
                    
                    # ë§¤ì¥ ì •ë³´ ì¡°íšŒ
                    main_store = self.store_service.data.get("store", {})
                    if main_store.get("store_id") == store_id:
                        store_images = main_store.get("store_images", [])
                        if store_images:
                            await broadcast_message({
                                "type": "show_images",
                                "content_type": "store",
                                "data": {
                                    "store_name": main_store.get("store_name", ""),
                                    "image_url": store_images[0],
                                    "address": main_store.get("address", "")
                                }
                            })
                            logger.info(f"âœ… Sent store image")
                    
                    # í…ìŠ¤íŠ¸ì—ì„œ íƒœê·¸ ì œê±° (TTSìš©)
                    text = re.sub(r'\[STORE:.*?\]', '', text).strip()
                
                # ë¸Œë¼ìš°ì €ë¡œ ì „ì†¡ (íƒœê·¸ ì œê±°ëœ í…ìŠ¤íŠ¸)
                await broadcast_message({
                    "type": "response",
                    "speaker": "assistant",
                    "text": text
                })
        
        await self.push_frame(frame, direction)


class OliveYoungVoiceBot:
    """ì˜¬ë¦¬ë¸Œì˜ ìŒì„± ì‡¼í•‘ ì–´ì‹œìŠ¤í„´íŠ¸ ë´‡"""
    
    def __init__(self):
        self.store_service = StoreService()
        
        # API í‚¤ í™•ì¸
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        if not self.openai_api_key:
            raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        self.cartesia_api_key = os.getenv("CARTESIA_API_KEY")
        if not self.cartesia_api_key:
            raise ValueError("CARTESIA_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        self.system_prompt = self._create_system_prompt()
    
    def _create_system_prompt(self) -> str:
        """ë´‡ì˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        
        # ë§¤ì¥ ì •ë³´
        main_store = self.store_service.data.get("store", {})
        store_name = main_store.get("store_name", "")
        store_address = main_store.get("address", "")
        store_phone = main_store.get("phone", "")
        subway_info = main_store.get("subway_info", "")
        
        # ì¸ê¸° ì œí’ˆ (í• ì¸ìœ¨ ë†’ì€ ìˆœ 5ê°œ, ID í¬í•¨)
        popular_products = self.store_service.get_popular_products(limit=5)
        products_summary = "\n".join([
            f"- [{p['product_id']}] {p['name'][:50]}... (í• ì¸ {p['discount_rate']}%, {p['sale_price']:,}ì›)"
            for p in popular_products
        ])
        
        # ì¹´í…Œê³ ë¦¬ ì •ë³´
        categories = self.store_service.get_categories()
        categories_summary = ", ".join(categories.keys())
        
        # ì¸ê·¼ ë§¤ì¥ (5ê°œë§Œ)
        nearby_stores = self.store_service.data.get("nearby_stores", [])[:5]
        nearby_summary = "\n".join([
            f"- {store.get('name', '')}: {store.get('address', '')}"
            for store in nearby_stores
        ])
        
        prompt = f"""ë‹¹ì‹ ì€ ì˜¬ë¦¬ë¸Œì˜(Olive Young)ì˜ ì¹œì ˆí•œ AI ì‡¼í•‘ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

[ì—­í• ]
- ê³ ê°ì—ê²Œ ì˜¬ë¦¬ë¸Œì˜ ë§¤ì¥ ì •ë³´ë¥¼ ì•ˆë‚´í•©ë‹ˆë‹¤
- ì œí’ˆ ì¶”ì²œê³¼ ì‡¼í•‘ ê´€ë ¨ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤
- í•­ìƒ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ ì‘ëŒ€í•©ë‹ˆë‹¤
- ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì²´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤

[ë©”ì¸ ë§¤ì¥ ì •ë³´]
ë§¤ì¥ëª…: {store_name}
ë§¤ì¥ID: D176
ì£¼ì†Œ: {store_address}
ì „í™”: {store_phone}
ì§€í•˜ì² : {subway_info}

[í˜„ì¬ ì¸ê¸° ì œí’ˆ TOP 5]
{products_summary}

[ì œí’ˆ ì¹´í…Œê³ ë¦¬]
{categories_summary}

[ì¸ê·¼ ë§¤ì¥ (ì°¸ê³ ìš©)]
{nearby_summary}

[ì´ë¯¸ì§€ í‘œì‹œ ê·œì¹™ - ì ˆëŒ€ í•„ìˆ˜!]
**ì œí’ˆ ì¶”ì²œ ì‹œ ì‘ë‹µ ë§ˆì§€ë§‰ì— PRODUCTS íƒœê·¸ë¥¼ 100% ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤!**
**ë§¤ì¥ ì •ë³´ ì‹œ ì‘ë‹µ ë§ˆì§€ë§‰ì— STORE íƒœê·¸ë¥¼ 100% ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤!**

í˜•ì‹:
- ì œí’ˆ: [PRODUCTS:ì œí’ˆID1,ì œí’ˆID2,ì œí’ˆID3]
- ë§¤ì¥: [STORE:ë§¤ì¥ID]

í•„ìˆ˜ ì˜ˆì‹œ:
Q: "ì œí’ˆ ì¶”ì²œí•´ì¤˜"
A: "í† ë¦¬ë“  ì„¸ëŸ¼ê³¼ ë‹¬ë°” ì„¸ëŸ¼ ì¶”ì²œë“œë¦½ë‹ˆë‹¤. [PRODUCTS:A000000189261,A000000232724]"

Q: "ì¸ê¸° ì œí’ˆ ë­ì•¼?"
A: "ì—ìŠ¤íŠ¸ë¼ í¬ë¦¼, í† ë¦¬ë“  ì„¸ëŸ¼, ë‹¬ë°” ì„¸ëŸ¼ì´ ì¸ê¸°ì…ë‹ˆë‹¤. [PRODUCTS:A000000236338,A000000189261,A000000232724]"

Q: "ë§¤ì¥ ìœ„ì¹˜ ì•Œë ¤ì¤˜"
A: "ì„œìš¸ ì¤‘êµ¬ ëª…ë™ê¸¸ 53ì— ìˆìŠµë‹ˆë‹¤. ëª…ë™ì—­ 8ë²ˆ ì¶œêµ¬ì…ë‹ˆë‹¤. [STORE:D176]"

**íƒœê·¸ ì—†ì´ ë‹µë³€í•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤! ë°˜ë“œì‹œ ì¶”ê°€í•˜ì„¸ìš”!**

[ì‘ëŒ€ ê°€ì´ë“œë¼ì¸]
1. ê³ ê°ì˜ ì§ˆë¬¸ì„ ì •í™•íˆ ì´í•´í•˜ê³  ê´€ë ¨ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”
2. ë§¤ì¥ ìœ„ì¹˜ë¥¼ ë¬¼ìœ¼ë©´ ì£¼ì†Œì™€ ì§€í•˜ì²  ì •ë³´ë¥¼ ì•ˆë‚´í•˜ì„¸ìš”
3. ì˜ì—…ì‹œê°„, ì „í™”ë²ˆí˜¸ ë“± êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ëª…í™•íˆ ì „ë‹¬í•˜ì„¸ìš”
4. **ì œí’ˆ ì¶”ì²œ ì‹œ: 2-3ê°œ ì†Œê°œ â†’ ë°˜ë“œì‹œ [PRODUCTS:ID1,ID2,ID3] ì¶”ê°€**
5. **ë§¤ì¥ ì •ë³´ ì‹œ: ì£¼ì†Œ ì•ˆë‚´ â†’ ë°˜ë“œì‹œ [STORE:D176] ì¶”ê°€**
6. **ì‘ë‹µì€ 20-30ì´ˆ ì´ë‚´ë¡œ ë§¤ìš° ì§§ê³  ê°„ê²°í•˜ê²Œ**
   - í•µì‹¬ ì •ë³´ë§Œ 2-3ë¬¸ì¥
   - ê¸´ ì„¤ëª… ê¸ˆì§€
7. [PRODUCTS:...] [STORE:...] íƒœê·¸ëŠ” ìŒì„±ìœ¼ë¡œ ì½íˆì§€ ì•Šìœ¼ë¯€ë¡œ ê±±ì •í•˜ì§€ ë§ˆì„¸ìš”

[ì¤‘ìš”]
- ì‹¤ì œë¡œ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë§¤ì¥ì´ë‚˜ ì œí’ˆ ì •ë³´ë¥¼ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆì„¸ìš”
- ìœ„ì— ëª…ì‹œëœ ì •ë³´ë§Œ ì‚¬ìš©í•˜ì„¸ìš”
- ê°€ê²© ì •ë³´ëŠ” ì°¸ê³ ìš©ìœ¼ë¡œë§Œ ì œê³µ (ì‹¤ì‹œê°„ ë³€ê²½ ê°€ëŠ¥)
- ì˜ë£Œì  ì¡°ì–¸ì´ë‚˜ ì§„ë‹¨ì€ í•˜ì§€ ë§ˆì„¸ìš”"""
        
        return prompt
    
    async def run(self, room_url: str, token: str = None, language: str = "ko"):
        """
        ë´‡ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
        
        Args:
            room_url: Daily.co ë£¸ URL
            token: ì¸ì¦ í† í° (ì„ íƒì‚¬í•­)
            language: STT ì–¸ì–´ ì„¤ì • (ko/en, ê¸°ë³¸ê°’: ko)
        """
        logger.info(f"Starting Olive Young Voice Assistant Bot (Language: {language})")
        
        # Daily transport ì„¤ì •
        transport = DailyTransport(
            room_url,
            token,
            "ì˜¬ë¦¬ë¸Œì˜ ì‡¼í•‘ ì–´ì‹œìŠ¤í„´íŠ¸",
            DailyParams(
                audio_in_enabled=True,
                audio_out_enabled=True,
                transcription_enabled=False,  # OpenAI Whisperë§Œ ì‚¬ìš© (Daily transcription ë”)
                vad_enabled=True,
                vad_analyzer=SileroVADAnalyzer(params=VADParams(stop_secs=0.2))
            ),
        )
        
        # STT ì„œë¹„ìŠ¤ - OpenAI Whisper (í•œêµ­ì–´ ì¸ì‹ ìµœê³ !)
        stt = OpenAISTTService(
            api_key=self.openai_api_key,
            model="whisper-1",
            language=language  # ko/en - WhisperëŠ” í•œêµ­ì–´ ì¸ì‹ì´ ë§¤ìš° ì •í™•
        )
        
        # TTS ì„œë¹„ìŠ¤ (í…ìŠ¤íŠ¸ â†’ ìŒì„±) - Cartesia
        # í•œêµ­ì–´ ì—¬ì„± ìŒì„± ì˜µì…˜:
        # - 248be419-c632-4f23-adf1-5324ed7dbf1d (Jiwon - ì Šê³  í™œê¸°ì°¬, ëª…í™•í•¨) âœ“
        # - a8a1eb38-5f15-4c1d-8722-7ac0f329727d (Soyeon - ë¶€ë“œëŸ½ê³  ìì—°ìŠ¤ëŸ¬ìš´)
        # ì˜ì–´ ì—¬ì„± ìŒì„± ì˜µì…˜:
        # - 21b81c14-f85b-436d-aff5-43f2e788ecf8 (Sarah - ëª…í™•í•˜ê³  í™œê¸°ì°¬) âœ“
        # - 02070f63-4fd3-4b03-a8cf-ac1e4a1e5c4c (Natasha - ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ)
        voice_id = "248be419-c632-4f23-adf1-5324ed7dbf1d" if language == "ko" else "21b81c14-f85b-436d-aff5-43f2e788ecf8"
        tts = CartesiaTTSService(
            api_key=self.cartesia_api_key,
            voice_id=voice_id,  # ëª…í™•í•˜ê³  í™œê¸°ì°¬ ì—¬ì„± ìŒì„±
        )
        
        # LLM ì„œë¹„ìŠ¤ (ëŒ€í™” ì²˜ë¦¬) - OpenAI
        llm = OpenAILLMService(
            api_key=self.openai_api_key,
            model="gpt-4o-mini"
        )
        
        # ë©”ì‹œì§€ ì´ˆê¸°í™” (few-shot ì˜ˆì œ í¬í•¨)
        messages = [
            {
                "role": "system",
                "content": self.system_prompt
            },
            # Few-shot ì˜ˆì œ 1: ì œí’ˆ ì¶”ì²œ
            {
                "role": "user",
                "content": "ì¸ê¸° ì œí’ˆ ì¶”ì²œí•´ì¤˜"
            },
            {
                "role": "assistant",
                "content": "í† ë¦¬ë“  ë‹¤ì´ë¸Œì¸ íˆì•Œë£¨ë¡ ì‚° ì„¸ëŸ¼ê³¼ ë‹¬ë°” í¼ìŠ¤íŠ¸ ìŠ¤í”„ë ˆì´ ì„¸ëŸ¼ ì¶”ì²œë“œë¦½ë‹ˆë‹¤. [PRODUCTS:A000000189261,A000000232724]"
            },
            # Few-shot ì˜ˆì œ 2: ë§¤ì¥ ì •ë³´
            {
                "role": "user",
                "content": "ë§¤ì¥ ì–´ë”” ìˆì–´?"
            },
            {
                "role": "assistant",
                "content": "ì„œìš¸ ì¤‘êµ¬ ëª…ë™ê¸¸ 53ì— ìˆìŠµë‹ˆë‹¤. ëª…ë™ì—­ 8ë²ˆ ì¶œêµ¬ë¡œ ë‚˜ì˜¤ì‹œë©´ ë©ë‹ˆë‹¤. [STORE:D176]"
            },
            # Few-shot ì˜ˆì œ 3: ì œí’ˆ ì¶”ì²œ (ë‹¤ë¥¸ ì˜ˆì‹œ)
            {
                "role": "user",
                "content": "ìŠ¤í‚¨ì¼€ì–´ ì œí’ˆ ì¶”ì²œ"
            },
            {
                "role": "assistant",
                "content": "ì—ìŠ¤íŠ¸ë¼ ì•„í† ë² ë¦¬ì–´ í¬ë¦¼, ë¼ë¡œìŠˆí¬ì œ ì‹œì¹´í”Œë¼ìŠ¤íŠ¸, ì›°ë¼ì¥¬ íˆì•Œë£¨ë¡œë‹‰ ì•°í”Œ ì¶”ì²œë“œë¦½ë‹ˆë‹¤. [PRODUCTS:A000000236338,A000000236101,A000000235247]"
            }
        ]
        
        # ì‚¬ìš©ì/ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ì§‘ê³„ê¸°
        user_response_aggregator = LLMUserResponseAggregator(messages)
        assistant_response_aggregator = LLMAssistantResponseAggregator(messages)
        
        # ì˜ë„ íŒë‹¨ í•„í„° (íŒë‹¨ LLMìœ¼ë¡œ AI ì–´ì‹œìŠ¤í„´íŠ¸ í˜¸ì¶œ ì˜ë„ íŒë‹¨)
        intent_filter = IntentDetectionFilter(self.openai_api_key)
        
        # ëŒ€í™” ë‚´ìš© ë¡œê±° (ì „ì—­ WebSocket ë§¤ë‹ˆì € ì‚¬ìš©) - Intent:YESë§Œ ê¸°ë¡
        transcript_logger = TranscriptLogger()
        
        # íŒŒì´í”„ë¼ì¸ êµ¬ì„± (OpenAI Whisper STT ì‚¬ìš©)
        pipeline = Pipeline(
            [
                transport.input(),           # ì˜¤ë””ì˜¤ ì…ë ¥
                stt,                         # OpenAI Whisper (í•œêµ­ì–´/ì˜ì–´ ìë™ ê°ì§€)
                intent_filter,               # ì˜ë„ íŒë‹¨ LLM (í•„í„°ë§) - NOëŠ” ì—¬ê¸°ì„œ ì°¨ë‹¨
                transcript_logger,           # ë¡œê¹… (Intent:YESë§Œ ê¸°ë¡)
                user_response_aggregator,    # ì‚¬ìš©ì ë©”ì‹œì§€ ì§‘ê³„
                llm,                         # ì‘ë‹µ LLM (ì‹¤ì œ ë‹µë³€)
                tts,                         # í…ìŠ¤íŠ¸ â†’ ìŒì„±
                transport.output(),          # ì˜¤ë””ì˜¤ ì¶œë ¥
                assistant_response_aggregator  # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ì§‘ê³„
            ]
        )
        
        # íŒŒì´í”„ë¼ì¸ íƒœìŠ¤í¬ ìƒì„±
        task = PipelineTask(
            pipeline,
            params=PipelineParams(
                allow_interruptions=False,  # TTS ì™„ë£Œê¹Œì§€ ì¤‘ë‹¨ ë°©ì§€
                enable_metrics=True,
                enable_usage_metrics=True,
            ),
        )
        
        # ì²« ì°¸ê°€ì ì…ì¥ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
        @transport.event_handler("on_first_participant_joined")
        async def on_first_participant_joined(transport, participant):
            logger.info(f"âœ… First participant joined: {participant['id']}")
            # OpenAI Whisper ì‚¬ìš©í•˜ë¯€ë¡œ Daily transcription ë¶ˆí•„ìš”
            # ì´ˆê¸° ì¸ì‚¬ë§
            logger.info("Sending initial greeting")
            messages.append({
                "role": "system",
                "content": "ì•ˆë…•í•˜ì„¸ìš”! ì˜¬ë¦¬ë¸Œì˜ ì‡¼í•‘ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë§¤ì¥ ì •ë³´ë‚˜ ì œí’ˆ ì¶”ì²œì´ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”."
            })
        
        # ì°¸ê°€ì í‡´ì¥ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
        @transport.event_handler("on_participant_left")
        async def on_participant_left(transport, participant, reason):
            logger.info(f"âŒ Participant left: {participant}")
            await task.queue_frame(EndFrame())
        
        # ë´‡ ì‹¤í–‰
        runner = PipelineRunner()
        await runner.run(task)


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (í…ŒìŠ¤íŠ¸ìš©)"""
    room_url = os.getenv("DAILY_ROOM_URL")
    if not room_url:
        logger.error("DAILY_ROOM_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    bot = OliveYoungVoiceBot()
    await bot.run(room_url)


if __name__ == "__main__":
    asyncio.run(main())

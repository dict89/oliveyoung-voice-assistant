"""
ì˜¬ë¦¬ë¸Œì˜ ìŒì„± ì‡¼í•‘ ì–´ì‹œìŠ¤í„´íŠ¸ ë´‡
Pipecatì„ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ ìŒì„± ëŒ€í™” êµ¬í˜„ (Daily.co Transport)
"""
import asyncio
import os
import sys

from pipecat.audio.vad.silero import SileroVADAnalyzer
from pipecat.audio.vad.vad_analyzer import VADParams
from pipecat.frames.frames import (
    EndFrame,
    TranscriptionFrame,
    TextFrame,
    Frame,
)
from pipecat.pipeline.pipeline import Pipeline
from pipecat.pipeline.runner import PipelineRunner
from pipecat.pipeline.task import PipelineParams, PipelineTask
from pipecat.processors.aggregators.llm_response import (
    LLMAssistantResponseAggregator,
    LLMUserResponseAggregator,
)
from pipecat.processors.frame_processor import FrameDirection, FrameProcessor
from pipecat.services.cartesia.tts import CartesiaTTSService
from pipecat.services.openai.llm import OpenAILLMService
from pipecat.services.openai.stt import OpenAISTTService
from pipecat.transports.daily.transport import DailyParams, DailyTransport

from loguru import logger
from dotenv import load_dotenv

from .store_service import StoreService
from .websocket_manager import broadcast_message

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê±° ì„¤ì •
logger.remove(0)
logger.add(sys.stderr, level="INFO")


class IntentDetectionFilter(FrameProcessor):
    """í•˜ì´ë¸Œë¦¬ë“œ ì˜ë„ íŒë‹¨ í•„í„°: ë¹ ë¥¸ í‚¤ì›Œë“œ ì²´í¬ + LLM ë°±ì—…"""
    
    # í™•ì‹¤í•œ YES í‚¤ì›Œë“œ (ì¦‰ì‹œ í†µê³¼)
    DEFINITE_YES_KEYWORDS = [
        "ì•ˆë…•", "ì¶”ì²œ", "ì•Œë ¤", "ì°¾ì•„", "ë„ì™€", "ì§ˆë¬¸", "ë¬¸ì˜",
        "ì–´ë””", "ìœ„ì¹˜", "ë§¤ì¥", "ì œí’ˆ", "ì˜ì—…", "ì‹œê°„", "ì—°ë½",
        "hello", "hi", "hey", "help", "recommend", "where", "store",
        "product", "location", "contact", "popular", "ì¸ê¸°"
    ]
    
    # í™•ì‹¤í•œ NO íŒ¨í„´ (ì¦‰ì‹œ ì°¨ë‹¨)
    DEFINITE_NO_PATTERNS = [
        "mbc ë‰´ìŠ¤", "kbs", "sbs", "ìë§‰", "êµ¬ë…", "ì¢‹ì•„ìš”",
        "ì‹œì²­", "ê°ì‚¬í•©ë‹ˆë‹¤", "ìˆ˜ê³ ", "ì˜ ë¨¹ê² ìŠµë‹ˆë‹¤"
    ]
    
    def __init__(self, openai_api_key: str):
        super().__init__()
        self.openai_api_key = openai_api_key
        
        # íŒë‹¨ìš© LLM (ë¶ˆëª…í™•í•œ ê²½ìš°ë§Œ ì‚¬ìš©)
        from openai import AsyncOpenAI
        self.client = AsyncOpenAI(api_key=openai_api_key)
        
        self.intent_prompt = """You are an intent classifier for an AI shopping assistant.

Respond with ONLY one word: "YES" or "NO"

YES = User is talking to the AI assistant (asking questions, requesting help)
NO = User is having a side conversation or not addressing the assistant

User input: "{text}"

Your answer (YES or NO):"""
    
    def _quick_keyword_check(self, text: str) -> str:
        """ë¹ ë¥¸ í‚¤ì›Œë“œ ì²´í¬ (ë°€ë¦¬ì´ˆ ë‹¨ìœ„)
        
        Returns:
            "YES" - í™•ì‹¤íˆ AIì—ê²Œ í•˜ëŠ” ë§
            "NO" - í™•ì‹¤íˆ AIì—ê²Œ í•˜ëŠ” ë§ì´ ì•„ë‹˜
            "UNCLEAR" - ë¶ˆëª…í™•, LLM íŒë‹¨ í•„ìš”
        """
        text_lower = text.lower()
        
        # 1. í™•ì‹¤í•œ NO íŒ¨í„´ ì²´í¬ (ê°€ì¥ ë¨¼ì €)
        for pattern in self.DEFINITE_NO_PATTERNS:
            if pattern in text_lower:
                return "NO"
        
        # 2. í™•ì‹¤í•œ YES í‚¤ì›Œë“œ ì²´í¬
        for keyword in self.DEFINITE_YES_KEYWORDS:
            if keyword in text_lower:
                return "YES"
        
        # 3. ë§¤ìš° ì§§ì€ ë¬¸ì¥ì€ ë³´í†µ AIì—ê²Œ í•˜ëŠ” ë§ì´ ì•„ë‹˜
        if len(text.strip()) < 5:
            return "NO"
        
        # 4. ë¶ˆëª…í™•í•œ ê²½ìš° (LLM í•„ìš”)
        return "UNCLEAR"
    
    async def _check_intent_with_llm(self, text: str) -> bool:
        """LLMìœ¼ë¡œ ì˜ë„ íŒë‹¨ (ë¶ˆëª…í™•í•œ ê²½ìš°ë§Œ í˜¸ì¶œ)"""
        try:
            response = await self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "user", "content": self.intent_prompt.format(text=text)}
                ],
                temperature=0,
                max_tokens=5
            )
            
            answer = response.choices[0].message.content.strip().upper()
            return answer == "YES"
            
        except Exception as e:
            logger.error(f"âŒ Intent detection error: {e}")
            return True  # ì˜¤ë¥˜ ì‹œ í†µê³¼
    
    async def process_frame(self, frame: Frame, direction: FrameDirection):
        await super().process_frame(frame, direction)
        
        # TranscriptionFrameë§Œ í•„í„°ë§
        if isinstance(frame, TranscriptionFrame):
            text = frame.text
            
            if text and text.strip() and len(text.strip()) > 1:
                # Step 1: ë¹ ë¥¸ í‚¤ì›Œë“œ ì²´í¬ (ë°€ë¦¬ì´ˆ)
                quick_result = self._quick_keyword_check(text)
                
                if quick_result == "YES":
                    logger.info(f"âœ… [KEYWORD: YES] Fast pass: {text}")
                    await self.push_frame(frame, direction)
                    return
                elif quick_result == "NO":
                    logger.info(f"â­ï¸ [KEYWORD: NO] Fast reject: {text}")
                    return
                else:
                    # Step 2: ë¶ˆëª…í™•í•œ ê²½ìš°ë§Œ LLM ì‚¬ìš©
                    logger.info(f"ğŸ¤” [UNCLEAR] Checking with LLM: {text}")
                    should_respond = await self._check_intent_with_llm(text)
                    
                    if should_respond:
                        logger.info(f"âœ… [LLM: YES] Forwarding to LLM: {text}")
                        await self.push_frame(frame, direction)
                    else:
                        logger.info(f"â­ï¸ [LLM: NO] Ignoring: {text}")
            else:
                return
        else:
            # ë‹¤ë¥¸ í”„ë ˆì„ì€ ê·¸ëŒ€ë¡œ ì „ë‹¬
            await self.push_frame(frame, direction)


class TranscriptLogger(FrameProcessor):
    """ëŒ€í™” ë‚´ìš©ì„ WebSocketìœ¼ë¡œ ì „ì†¡í•˜ëŠ” í”„ë¡œì„¸ì„œ (Intent:YESë§Œ ë„ë‹¬)"""
    
    async def process_frame(self, frame: Frame, direction: FrameDirection):
        await super().process_frame(frame, direction)
        
        # STT ê²°ê³¼ (ì‚¬ìš©ì ìŒì„± ì¸ì‹) - Intent:YESì¸ ê²ƒë§Œ ì—¬ê¸° ë„ë‹¬
        if isinstance(frame, TranscriptionFrame):
            text = frame.text
            # ë¹ˆ ë¬¸ìì—´ì´ë‚˜ ê³µë°±ë§Œ ìˆëŠ” ê²½ìš° ë¬´ì‹œ
            if text and text.strip() and len(text.strip()) > 1:
                # ë¸Œë¼ìš°ì € ì±„íŒ…ì°½ìœ¼ë¡œë§Œ ì „ì†¡ (ë¡œê·¸ëŠ” IntentDetectionFilterì—ì„œ ì´ë¯¸ ì¶œë ¥)
                await broadcast_message({
                    "type": "transcript",
                    "speaker": "user",
                    "text": text.strip()  # ê³µë°± ì œê±°
                })
        
        # LLM ì‘ë‹µ í…ìŠ¤íŠ¸
        elif isinstance(frame, TextFrame):
            text = frame.text
            if text and text.strip():
                logger.info(f"ğŸ¤– [ASSISTANT]: {text}")
                # ë¸Œë¼ìš°ì €ë¡œ ì „ì†¡ (ì „ì—­ WebSocket ë§¤ë‹ˆì € ì‚¬ìš©)
                await broadcast_message({
                    "type": "response",
                    "speaker": "assistant",
                    "text": text
                })
        
        await self.push_frame(frame, direction)


class OliveYoungVoiceBot:
    """ì˜¬ë¦¬ë¸Œì˜ ìŒì„± ì‡¼í•‘ ì–´ì‹œìŠ¤í„´íŠ¸ ë´‡"""
    
    def __init__(self):
        self.store_service = StoreService()
        
        # API í‚¤ í™•ì¸
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        if not self.openai_api_key:
            raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        self.cartesia_api_key = os.getenv("CARTESIA_API_KEY")
        if not self.cartesia_api_key:
            raise ValueError("CARTESIA_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        self.system_prompt = self._create_system_prompt()
    
    def _create_system_prompt(self) -> str:
        """ë´‡ì˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        
        # ë§¤ì¥ ì •ë³´ ìš”ì•½
        stores_summary = "\n".join([
            f"- {store['name']} ({store['store_id']}): {store['address']}"
            for store in self.store_service.get_all_stores()
        ])
        
        # ì¹´í…Œê³ ë¦¬ ì •ë³´
        categories = self.store_service.get_categories()
        categories_summary = ", ".join(categories.keys())
        
        prompt = f"""ë‹¹ì‹ ì€ ì˜¬ë¦¬ë¸Œì˜(Olive Young)ì˜ ì¹œì ˆí•œ AI ì‡¼í•‘ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

[ì—­í• ]
- ê³ ê°ì—ê²Œ ì˜¬ë¦¬ë¸Œì˜ ë§¤ì¥ ì •ë³´ë¥¼ ì•ˆë‚´í•©ë‹ˆë‹¤
- ì œí’ˆ ì¶”ì²œê³¼ ì‡¼í•‘ ê´€ë ¨ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤
- í•­ìƒ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ ì‘ëŒ€í•©ë‹ˆë‹¤
- ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì²´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤

[ì œê³µ ê°€ëŠ¥í•œ ì •ë³´]
1. ë§¤ì¥ ìœ„ì¹˜, ì˜ì—…ì‹œê°„, ì—°ë½ì²˜
2. ë§¤ì¥ë³„ íŠ¹ì§• ë° ì œê³µ ì„œë¹„ìŠ¤
3. êµí†µ ì •ë³´ ë° ì£¼ë³€ ëœë“œë§ˆí¬
4. ì¸ê¸° ì œí’ˆ ë° ì¶”ì²œ
5. ì œí’ˆ ì¹´í…Œê³ ë¦¬: {categories_summary}

[í˜„ì¬ ë“±ë¡ëœ ë§¤ì¥]
{stores_summary}

[ì‘ëŒ€ ê°€ì´ë“œë¼ì¸]
1. ê³ ê°ì˜ ì§ˆë¬¸ì„ ì •í™•íˆ ì´í•´í•˜ê³  ê´€ë ¨ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”
2. ë§¤ì¥ ìœ„ì¹˜ë¥¼ ë¬¼ìœ¼ë©´ ì£¼ì†Œì™€ í•¨ê»˜ ê°€ê¹Œìš´ ì§€í•˜ì² ì—­ì´ë‚˜ ëœë“œë§ˆí¬ë¥¼ ì•ˆë‚´í•˜ì„¸ìš”
3. ì˜ì—…ì‹œê°„, ì „í™”ë²ˆí˜¸ ë“± êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ëª…í™•íˆ ì „ë‹¬í•˜ì„¸ìš”
4. ì œí’ˆ ì¶”ì²œ ì‹œì—ëŠ” 2-3ê°œë§Œ ê°„ë‹¨íˆ ì†Œê°œí•˜ì„¸ìš”
5. ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ì†”ì§íˆ ë§í•˜ê³  ë‹¤ë¥¸ ë°©ë²•ì„ ì œì•ˆí•˜ì„¸ìš”
6. **ì‘ë‹µì€ 20-30ì´ˆ ì´ë‚´ë¡œ ë§¤ìš° ì§§ê³  ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš” (ìŒì„± ëŒ€í™”)**
   - í•µì‹¬ ì •ë³´ë§Œ 2-3ë¬¸ì¥ìœ¼ë¡œ ì „ë‹¬
   - ê¸´ ì„¤ëª… ê¸ˆì§€
   - ë¶ˆí•„ìš”í•œ ì¸ì‚¬ë§ ìµœì†Œí™”
7. íŠ¹ìˆ˜ ë¬¸ìëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš” (ìŒì„±ìœ¼ë¡œ ë³€í™˜ë˜ë¯€ë¡œ)

[ì¤‘ìš”]
- ì‹¤ì œë¡œ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë§¤ì¥ì´ë‚˜ ì œí’ˆ ì •ë³´ë¥¼ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆì„¸ìš”
- ìœ„ì— ëª…ì‹œëœ ë§¤ì¥ ì •ë³´ë§Œ ì‚¬ìš©í•˜ì„¸ìš”
- ê°€ê²© ì •ë³´ëŠ” ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ (ì‹¤ì‹œê°„ìœ¼ë¡œ ë³€ê²½ë  ìˆ˜ ìˆìŒ)
- ì˜ë£Œì  ì¡°ì–¸ì´ë‚˜ ì§„ë‹¨ì€ í•˜ì§€ ë§ˆì„¸ìš”"""
        
        return prompt
    
    async def run(self, room_url: str, token: str = None, language: str = "ko"):
        """
        ë´‡ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
        
        Args:
            room_url: Daily.co ë£¸ URL
            token: ì¸ì¦ í† í° (ì„ íƒì‚¬í•­)
            language: STT ì–¸ì–´ ì„¤ì • (ko/en, ê¸°ë³¸ê°’: ko)
        """
        logger.info(f"Starting Olive Young Voice Assistant Bot (Language: {language})")
        
        # Daily transport ì„¤ì •
        transport = DailyTransport(
            room_url,
            token,
            "ì˜¬ë¦¬ë¸Œì˜ ì‡¼í•‘ ì–´ì‹œìŠ¤í„´íŠ¸",
            DailyParams(
                audio_in_enabled=True,
                audio_out_enabled=True,
                transcription_enabled=False,  # OpenAI Whisperë§Œ ì‚¬ìš© (Daily transcription ë”)
                vad_enabled=True,
                vad_analyzer=SileroVADAnalyzer(params=VADParams(stop_secs=0.2))
            ),
        )
        
        # STT ì„œë¹„ìŠ¤ - OpenAI Whisper (í•œêµ­ì–´ ì¸ì‹ ìµœê³ !)
        stt = OpenAISTTService(
            api_key=self.openai_api_key,
            model="whisper-1",
            language=language  # ko/en - WhisperëŠ” í•œêµ­ì–´ ì¸ì‹ì´ ë§¤ìš° ì •í™•
        )
        
        # TTS ì„œë¹„ìŠ¤ (í…ìŠ¤íŠ¸ â†’ ìŒì„±) - Cartesia
        # í•œêµ­ì–´ ì—¬ì„± ìŒì„± ì˜µì…˜:
        # - 248be419-c632-4f23-adf1-5324ed7dbf1d (Jiwon - ì Šê³  í™œê¸°ì°¬, ëª…í™•í•¨) âœ“
        # - a8a1eb38-5f15-4c1d-8722-7ac0f329727d (Soyeon - ë¶€ë“œëŸ½ê³  ìì—°ìŠ¤ëŸ¬ìš´)
        # ì˜ì–´ ì—¬ì„± ìŒì„± ì˜µì…˜:
        # - 21b81c14-f85b-436d-aff5-43f2e788ecf8 (Sarah - ëª…í™•í•˜ê³  í™œê¸°ì°¬) âœ“
        # - 02070f63-4fd3-4b03-a8cf-ac1e4a1e5c4c (Natasha - ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ)
        voice_id = "248be419-c632-4f23-adf1-5324ed7dbf1d" if language == "ko" else "21b81c14-f85b-436d-aff5-43f2e788ecf8"
        tts = CartesiaTTSService(
            api_key=self.cartesia_api_key,
            voice_id=voice_id,  # ëª…í™•í•˜ê³  í™œê¸°ì°¬ ì—¬ì„± ìŒì„±
        )
        
        # LLM ì„œë¹„ìŠ¤ (ëŒ€í™” ì²˜ë¦¬) - OpenAI
        llm = OpenAILLMService(
            api_key=self.openai_api_key,
            model="gpt-4o-mini"
        )
        
        # ë©”ì‹œì§€ ì´ˆê¸°í™”
        messages = [
            {
                "role": "system",
                "content": self.system_prompt
            }
        ]
        
        # ì‚¬ìš©ì/ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ì§‘ê³„ê¸°
        user_response_aggregator = LLMUserResponseAggregator(messages)
        assistant_response_aggregator = LLMAssistantResponseAggregator(messages)
        
        # ì˜ë„ íŒë‹¨ í•„í„° (íŒë‹¨ LLMìœ¼ë¡œ AI ì–´ì‹œìŠ¤í„´íŠ¸ í˜¸ì¶œ ì˜ë„ íŒë‹¨)
        intent_filter = IntentDetectionFilter(self.openai_api_key)
        
        # ëŒ€í™” ë‚´ìš© ë¡œê±° (ì „ì—­ WebSocket ë§¤ë‹ˆì € ì‚¬ìš©) - Intent:YESë§Œ ê¸°ë¡
        transcript_logger = TranscriptLogger()
        
        # íŒŒì´í”„ë¼ì¸ êµ¬ì„± (OpenAI Whisper STT ì‚¬ìš©)
        pipeline = Pipeline(
            [
                transport.input(),           # ì˜¤ë””ì˜¤ ì…ë ¥
                stt,                         # OpenAI Whisper (í•œêµ­ì–´/ì˜ì–´ ìë™ ê°ì§€)
                intent_filter,               # ì˜ë„ íŒë‹¨ LLM (í•„í„°ë§) - NOëŠ” ì—¬ê¸°ì„œ ì°¨ë‹¨
                transcript_logger,           # ë¡œê¹… (Intent:YESë§Œ ê¸°ë¡)
                user_response_aggregator,    # ì‚¬ìš©ì ë©”ì‹œì§€ ì§‘ê³„
                llm,                         # ì‘ë‹µ LLM (ì‹¤ì œ ë‹µë³€)
                tts,                         # í…ìŠ¤íŠ¸ â†’ ìŒì„±
                transport.output(),          # ì˜¤ë””ì˜¤ ì¶œë ¥
                assistant_response_aggregator  # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ì§‘ê³„
            ]
        )
        
        # íŒŒì´í”„ë¼ì¸ íƒœìŠ¤í¬ ìƒì„±
        task = PipelineTask(
            pipeline,
            params=PipelineParams(
                allow_interruptions=False,  # TTS ì™„ë£Œê¹Œì§€ ì¤‘ë‹¨ ë°©ì§€
                enable_metrics=True,
                enable_usage_metrics=True,
            ),
        )
        
        # ì²« ì°¸ê°€ì ì…ì¥ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
        @transport.event_handler("on_first_participant_joined")
        async def on_first_participant_joined(transport, participant):
            logger.info(f"âœ… First participant joined: {participant['id']}")
            # OpenAI Whisper ì‚¬ìš©í•˜ë¯€ë¡œ Daily transcription ë¶ˆí•„ìš”
            # ì´ˆê¸° ì¸ì‚¬ë§
            logger.info("Sending initial greeting")
            messages.append({
                "role": "system",
                "content": "ì•ˆë…•í•˜ì„¸ìš”! ì˜¬ë¦¬ë¸Œì˜ ì‡¼í•‘ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë§¤ì¥ ì •ë³´ë‚˜ ì œí’ˆ ì¶”ì²œì´ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”."
            })
        
        # ì°¸ê°€ì í‡´ì¥ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
        @transport.event_handler("on_participant_left")
        async def on_participant_left(transport, participant, reason):
            logger.info(f"âŒ Participant left: {participant}")
            await task.queue_frame(EndFrame())
        
        # ë´‡ ì‹¤í–‰
        runner = PipelineRunner()
        await runner.run(task)


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (í…ŒìŠ¤íŠ¸ìš©)"""
    room_url = os.getenv("DAILY_ROOM_URL")
    if not room_url:
        logger.error("DAILY_ROOM_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    bot = OliveYoungVoiceBot()
    await bot.run(room_url)


if __name__ == "__main__":
    asyncio.run(main())

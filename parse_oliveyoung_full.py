#!/usr/bin/env python3
"""
ì˜¬ë¦¬ë¸Œì˜ HTML ì™„ì „ íŒŒì‹± - AI ì‡¼í•‘ ì–´ì‹œìŠ¤í„´íŠ¸ìš© ë°ì´í„° ìƒì„±

ì‚¬ìš©ë²•:
  python3 parse_oliveyoung_full.py oy_sample.html data/assistant_data.json
"""

import sys
import json
import re
from pathlib import Path
from bs4 import BeautifulSoup
from datetime import datetime


def parse_store_info(soup):
    """ë§¤ì¥ ì •ë³´ ì¶”ì¶œ"""
    store_info = {
        'store_name': '',
        'store_id': '',
        'address': '',
        'subway_info': '',
        'phone': '',
        'business_hours': {},
        'services': [],
        'gift_services': [],
        'store_images': [],
        'description': ''
    }
    
    # ë§¤ì¥ëª… - ë” ì •í™•í•œ ì„ íƒì ì‚¬ìš©
    store_name_elem = soup.select_one('.tit_zone .tit')
    if not store_name_elem:
        store_name_elem = soup.select_one('.store_info_detail .tit_zone .tit')
    if store_name_elem:
        store_info['store_name'] = store_name_elem.get_text(strip=True)
    
    # Store ID ì¶”ì¶œ (ë§í¬ì—ì„œ)
    store_link = soup.select_one('a[href*="getStockStoreDetail"]')
    if store_link:
        href = store_link.get('href', '')
        # javascript:storeInfos.storeDetail.getStockStoreDetail('D176', 'ì˜¬ë¦¬ë¸Œì˜ ëª…ë™ íƒ€ìš´')
        match = re.search(r"getStockStoreDetail\('([^']+)'", href)
        if match:
            store_info['store_id'] = match.group(1)
    
    # ë§¤ì¥ ì„¤ëª…
    desc_elem = soup.select_one('.shop_detail_txt dd')
    if desc_elem:
        store_info['description'] = desc_elem.get_text(strip=True)
    
    # ì£¼ì†Œ
    address_elem = soup.select_one('._address')
    if address_elem:
        store_info['address'] = address_elem.get_text(strip=True)
    
    # ì§€í•˜ì²  ì •ë³´
    subway_elem = soup.select_one('.addr .sub')
    if subway_elem:
        store_info['subway_info'] = subway_elem.get_text(strip=True)
    
    # ì „í™”ë²ˆí˜¸
    phone_elem = soup.select_one('._shopTel')
    if phone_elem:
        store_info['phone'] = phone_elem.get_text(strip=True)
    
    # ì˜ì—…ì‹œê°„
    workday_list = soup.select('._workdayList li')
    for item in workday_list:
        day = item.select_one('strong')
        time = item.select_one('span')
        if day and time:
            day_text = day.get_text(strip=True)
            time_text = time.get_text(strip=True)
            store_info['business_hours'][day_text] = time_text
    
    # ë§¤ì¥ ì„œë¹„ìŠ¤
    service_list = soup.select('._storeServiceList li')
    store_info['services'] = [s.get_text(strip=True) for s in service_list]
    
    # ìƒí’ˆê¶Œ íŒë§¤
    gift_list = soup.select('._giftServiceList li')
    store_info['gift_services'] = [g.get_text(strip=True) for g in gift_list]
    
    # ë§¤ì¥ ì´ë¯¸ì§€
    store_img_elem = soup.select_one('#storeDetailImage')
    if store_img_elem:
        style = store_img_elem.get('style', '')
        # background-image: url("...") ì—ì„œ URL ì¶”ì¶œ
        urls = re.findall(r'url\(["\']?(https?://[^)"\']+)["\']?\)', style)
        store_info['store_images'] = [url for url in urls if 'noimg' not in url]
    
    return store_info


def parse_products(soup):
    """ìƒí’ˆ ì •ë³´ ì¶”ì¶œ"""
    products = []
    
    # stockGoodsListì—ì„œ ìƒí’ˆ ì°¾ê¸°
    product_items = soup.select('#stockGoodsList li')
    
    print(f"âœ… {len(product_items)}ê°œ ìƒí’ˆ ë°œê²¬")
    
    for idx, item in enumerate(product_items, 1):
        try:
            product = {}
            
            # ìƒí’ˆ ë²ˆí˜¸
            link = item.select_one('a[data-goodsno]')
            if link:
                product['product_id'] = link.get('data-goodsno', '')
            else:
                product['product_id'] = ''
            
            # ìƒí’ˆëª…
            tit_elem = item.select_one('.tit')
            if tit_elem:
                product['name'] = tit_elem.get_text(strip=True)
            else:
                product['name'] = ''
            
            # ìƒí’ˆ ì´ë¯¸ì§€
            img = item.select_one('.img_zone img')
            if img:
                product['image_url'] = img.get('src', '')
            else:
                product['image_url'] = ''
            
            # ê°€ê²© ì •ë³´
            price_zone = item.select_one('.price')
            
            # ì •ê°€ (pre)
            pre_elem = price_zone.select_one('.pre') if price_zone else None
            if pre_elem:
                price_text = pre_elem.get_text(strip=True)
                price_text = re.sub(r'[^\d]', '', price_text)
                product['original_price'] = int(price_text) if price_text else 0
            else:
                product['original_price'] = 0
            
            # í• ì¸ìœ¨ (per)
            per_elem = price_zone.select_one('.per') if price_zone else None
            if per_elem:
                discount_text = per_elem.get_text(strip=True)
                discount_text = re.sub(r'[^\d]', '', discount_text)
                product['discount_rate'] = int(discount_text) if discount_text else 0
            else:
                product['discount_rate'] = 0
            
            # ìµœì¢…ê°€ê²© (coast)
            coast_elem = price_zone.select_one('.coast') if price_zone else None
            if coast_elem:
                # "25,650ì›~" í˜•íƒœì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œ
                coast_text = coast_elem.get_text(strip=True)
                coast_text = re.sub(r'[^\d]', '', coast_text)
                product['sale_price'] = int(coast_text) if coast_text else 0
            else:
                product['sale_price'] = 0
            
            # ì¬ê³  ì •ë³´ (btnStoreStockMainGoodsDetail)
            stock_btn = item.select_one('._btnStoreStockMainGoodsDetail .num')
            if stock_btn:
                stock_text = stock_btn.get_text(strip=True)
                product['stock_info'] = stock_text
                
                # ì¬ê³  ìƒíƒœ ë¶„ë¥˜
                if 'í’ˆì ˆ' in stock_text or 'ì¬ê³  ì—†ìŒ' in stock_text:
                    product['stock_status'] = 'í’ˆì ˆ'
                elif 'ì¬ê³ ' in stock_text:
                    if '9ê°œ ì´ìƒ' in stock_text:
                        product['stock_status'] = 'ì¬ê³ ìˆìŒ'
                    else:
                        # "ì¬ê³  3ê°œ" ê°™ì€ í˜•íƒœ
                        product['stock_status'] = 'ì¬ê³ ìˆìŒ'
                else:
                    product['stock_status'] = 'í™•ì¸í•„ìš”'
            else:
                product['stock_info'] = 'ì •ë³´ ì—†ìŒ'
                product['stock_status'] = 'í™•ì¸í•„ìš”'
            
            # ìƒí’ˆ ì •ë³´ê°€ ìœ íš¨í•œ ê²½ìš°ë§Œ ì¶”ê°€
            if product.get('name'):
                products.append(product)
                
        except Exception as e:
            print(f"  âš ï¸  ìƒí’ˆ {idx} ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            continue
    
    return products


def categorize_products(products):
    """ìƒí’ˆì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜"""
    
    categories = {
        'ìŠ¤í‚¨ì¼€ì–´': [],
        'ë©”ì´í¬ì—…': [],
        'ë§ˆìŠ¤í¬/íŒ©': [],
        'í´ë Œì§•': [],
        'ì„ ì¼€ì–´': [],
        'í—¤ì–´ì¼€ì–´': [],
        'ë°”ë””ì¼€ì–´': [],
        'í–¥ìˆ˜': [],
        'ê±´ê°•ì‹í’ˆ': [],
        'ê¸°íƒ€': []
    }
    
    # í‚¤ì›Œë“œ ë§¤í•‘
    keyword_map = {
        'ìŠ¤í‚¨ì¼€ì–´': ['ì„¸ëŸ¼', 'í† ë„ˆ', 'ì—ì„¼ìŠ¤', 'í¬ë¦¼', 'ë¡œì…˜', 'ì•°í”Œ', 'ë¯¸ìŠ¤íŠ¸', 'ìˆ˜ë¶„', 'ë³´ìŠµ'],
        'ë©”ì´í¬ì—…': ['í‹´íŠ¸', 'ë¦½', 'ì¿ ì…˜', 'íŒŒìš´ë°ì´ì…˜', 'ì»¨ì‹¤ëŸ¬', 'ì•„ì´', 'ì„€ë„ìš°', 'ë§ˆìŠ¤ì¹´ë¼', 'ì¹˜í¬', 'ì•„ì´ë¸Œë¡œìš°'],
        'ë§ˆìŠ¤í¬/íŒ©': ['ë§ˆìŠ¤í¬', 'íŒ©', 'ì‹œíŠ¸'],
        'í´ë Œì§•': ['í´ë Œì§•', 'ì„¸ì•ˆ', 'í¼', 'ì›Œì‹œ', 'ì ¤', 'ë°¤', 'ë¦¬ë¬´ë²„'],
        'ì„ ì¼€ì–´': ['ì„ í¬ë¦¼', 'ì„ ì¼€ì–´', 'ìì™¸ì„ ', 'SPF', 'ì¬'],
        'í—¤ì–´ì¼€ì–´': ['ìƒ´í‘¸', 'ë¦°ìŠ¤', 'íŠ¸ë¦¬íŠ¸ë¨¼íŠ¸', 'í—¤ì–´', 'ë‘í”¼'],
        'ë°”ë””ì¼€ì–´': ['ë°”ë””', 'í•¸ë“œ', 'í’‹', 'ë¡œì…˜', 'í¬ë¦¼', 'ì›Œì‹œ'],
        'í–¥ìˆ˜': ['í–¥ìˆ˜', 'í¼í“¸', 'í”„ë˜ê·¸ëŸ°ìŠ¤', 'ë””í“¨ì €'],
        'ê±´ê°•ì‹í’ˆ': ['ë¹„íƒ€ë¯¼', 'ì˜ì–‘ì œ', 'ê±´ê°•', 'ì½œë¼ê²', 'í”„ë¡œë°”ì´ì˜¤í‹±ìŠ¤']
    }
    
    for product in products:
        name = product['name'].lower()
        categorized = False
        
        for category, keywords in keyword_map.items():
            if any(kw in name for kw in keywords):
                categories[category].append(product)
                categorized = True
                break
        
        if not categorized:
            categories['ê¸°íƒ€'].append(product)
    
    # ë¹ˆ ì¹´í…Œê³ ë¦¬ ì œê±°
    return {k: v for k, v in categories.items() if v}


def parse_floor_map_info(soup):
    """ì¸µë³„ì•ˆë‚´ ì •ë³´ ì¶”ì¶œ"""
    floor_info = {
        'available': False,
        'floors': [],
        'map_element_id': 'townDabeoMap'
    }
    
    # ì¸µë³„ì•ˆë‚´ ë²„íŠ¼ ë¦¬ìŠ¤íŠ¸ í™•ì¸
    floor_btns = soup.select('#btnFloorList li')
    if floor_btns:
        floor_info['available'] = True
        floor_info['note'] = 'ì¸µë³„ì•ˆë‚´ ê¸°ëŠ¥ì´ ìˆìœ¼ë‚˜, ë™ì ìœ¼ë¡œ ë¡œë“œë˜ëŠ” ì§€ë„ ì´ë¯¸ì§€ëŠ” HTMLì—ì„œ ì¶”ì¶œ ë¶ˆê°€'
    
    return floor_info


def extract_nearby_stores(soup):
    """ì£¼ë³€ ë§¤ì¥ ëª©ë¡ ì¶”ì¶œ"""
    stores = []
    
    store_items = soup.select('#storeList li')
    
    for item in store_items:
        try:
            store = {}
            
            # ë§¤ì¥ëª…
            name_elem = item.select_one('.txt_tit')
            if name_elem:
                store['name'] = name_elem.get_text(strip=True)
            
            # ì£¼ì†Œ
            addr_elem = item.select_one('.txt_addr')
            if addr_elem:
                store['address'] = addr_elem.get_text(strip=True)
            
            # ì˜ì—… ìƒíƒœ
            status_elem = item.select_one('.txt_status .day')
            if status_elem:
                store['status'] = status_elem.get_text(strip=True)
            
            # ì˜ì—… ì‹œê°„
            time_elem = item.select_one('.txt_status .time')
            if time_elem:
                store['hours'] = time_elem.get_text(strip=True)
            
            # ë§¤ì¥ ì´ë¯¸ì§€
            img = item.select_one('.img_thubnail img')
            if img:
                store['image'] = img.get('src', '')
            
            # íƒœê·¸ (ì„œë¹„ìŠ¤)
            tags = item.select('.tags_area .tag')
            store['services'] = [tag.get_text(strip=True) for tag in tags]
            
            # Store ID ì¶”ì¶œ (ë§í¬ì—ì„œ)
            link = item.select_one('a[href*="getStockStoreDetail"]')
            if link:
                href = link.get('href', '')
                # javascript:storeInfos.storeDetail.getStockStoreDetail('D176', 'ì˜¬ë¦¬ë¸Œì˜ ëª…ë™ íƒ€ìš´')
                match = re.search(r"getStockStoreDetail\('([^']+)'", href)
                if match:
                    store['store_id'] = match.group(1)
            
            if store.get('name'):
                stores.append(store)
                
        except Exception as e:
            print(f"  âš ï¸  ë§¤ì¥ ì •ë³´ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            continue
    
    return stores


def main():
    if len(sys.argv) < 2:
        print("""
ì˜¬ë¦¬ë¸Œì˜ HTML ì™„ì „ íŒŒì‹± - AI ì‡¼í•‘ ì–´ì‹œìŠ¤í„´íŠ¸ìš©

ì‚¬ìš©ë²•:
  python3 parse_oliveyoung_full.py <html_file> [output_file]

ì˜ˆì‹œ:
  python3 parse_oliveyoung_full.py oy_sample.html data/assistant_data.json
        """)
        return
    
    html_file = sys.argv[1]
    output_file = sys.argv[2] if len(sys.argv) > 2 else 'data/assistant_data.json'
    
    if not Path(html_file).exists():
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {html_file}")
        return
    
    print("="*80)
    print("ğŸ›ï¸  ì˜¬ë¦¬ë¸Œì˜ AI ì‡¼í•‘ ì–´ì‹œìŠ¤í„´íŠ¸ ë°ì´í„° ìƒì„±")
    print("="*80 + "\n")
    
    # HTML ë¡œë“œ
    print(f"ğŸ“‚ HTML íŒŒì¼ ë¡œë“œ ì¤‘: {html_file}")
    with open(html_file, 'r', encoding='utf-8') as f:
        html_content = f.read()
    
    print(f"âœ… íŒŒì¼ í¬ê¸°: {len(html_content):,} bytes\n")
    
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # 1. ë§¤ì¥ ì •ë³´ ì¶”ì¶œ
    print("ğŸ¢ ë§¤ì¥ ì •ë³´ ì¶”ì¶œ ì¤‘...")
    store_info = parse_store_info(soup)
    print(f"   âœ… ë§¤ì¥ëª…: {store_info['store_name']}")
    print(f"   âœ… ì£¼ì†Œ: {store_info['address']}")
    print(f"   âœ… ì „í™”: {store_info['phone']}")
    print(f"   âœ… ì„œë¹„ìŠ¤: {', '.join(store_info['services'])}")
    print()
    
    # 2. ìƒí’ˆ ì •ë³´ ì¶”ì¶œ
    print("ğŸ›’ ìƒí’ˆ ì •ë³´ ì¶”ì¶œ ì¤‘...")
    products = parse_products(soup)
    print(f"   âœ… ì´ {len(products)}ê°œ ìƒí’ˆ ì¶”ì¶œ ì™„ë£Œ\n")
    
    # 3. ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
    print("ğŸ“¦ ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜ ì¤‘...")
    categorized = categorize_products(products)
    for cat, items in categorized.items():
        print(f"   âœ… {cat}: {len(items)}ê°œ")
    print()
    
    # 4. ì¸µë³„ì•ˆë‚´ ì •ë³´
    print("ğŸ—ºï¸  ì¸µë³„ì•ˆë‚´ ì •ë³´ ì¶”ì¶œ ì¤‘...")
    floor_info = parse_floor_map_info(soup)
    if floor_info['available']:
        print(f"   âœ… {floor_info.get('note', 'ì¸µë³„ì•ˆë‚´ ì •ë³´ ìˆìŒ')}")
    else:
        print(f"   â„¹ï¸  ì¸µë³„ì•ˆë‚´ ì •ë³´ ì—†ìŒ")
    print()
    
    # 5. ì£¼ë³€ ë§¤ì¥
    print("ğŸ“ ì£¼ë³€ ë§¤ì¥ ì •ë³´ ì¶”ì¶œ ì¤‘...")
    nearby_stores = extract_nearby_stores(soup)
    print(f"   âœ… {len(nearby_stores)}ê°œ ì£¼ë³€ ë§¤ì¥ ì •ë³´ ì¶”ì¶œ\n")
    
    # ìµœì¢… ë°ì´í„° êµ¬ì„±
    result = {
        'metadata': {
            'extracted_at': datetime.now().isoformat(),
            'extraction_method': 'html_parsing',
            'source_file': html_file,
            'version': '1.0'
        },
        'store': store_info,
        'products': {
            'total': len(products),
            'by_category': categorized,
            'all_products': products
        },
        'floor_map': floor_info,
        'nearby_stores': nearby_stores
    }
    
    # ì €ì¥
    output_path = Path(output_file)
    output_path.parent.mkdir(exist_ok=True, parents=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    # ê²°ê³¼ ìš”ì•½
    print("="*80)
    print("âœ… ì¶”ì¶œ ì™„ë£Œ!")
    print("="*80)
    print(f"\nğŸ“Š ì¶”ì¶œ ê²°ê³¼ ìš”ì•½:")
    print(f"   ğŸ¢ ë§¤ì¥ëª…: {store_info['store_name']}")
    print(f"   ğŸ“ ì£¼ì†Œ: {store_info['address']}")
    print(f"   ğŸ“ ì „í™”: {store_info['phone']}")
    print(f"   ğŸ›ï¸  ì´ ìƒí’ˆ: {len(products)}ê°œ")
    print(f"   ğŸ“¦ ì¹´í…Œê³ ë¦¬: {len(categorized)}ê°œ")
    print(f"   ğŸ¬ ì£¼ë³€ ë§¤ì¥: {len(nearby_stores)}ê°œ")
    print(f"\nğŸ’¾ ì €ì¥ ìœ„ì¹˜: {output_file}")
    
    # ìƒí’ˆ í†µê³„
    stock_available = sum(1 for p in products if p['stock_status'] == 'ì¬ê³ ìˆìŒ')
    stock_out = sum(1 for p in products if p['stock_status'] == 'í’ˆì ˆ')
    
    print(f"\nğŸ“ˆ ì¬ê³  í˜„í™©:")
    print(f"   âœ… ì¬ê³ ìˆìŒ: {stock_available}ê°œ")
    print(f"   âŒ í’ˆì ˆ: {stock_out}ê°œ")
    print(f"   âš ï¸  í™•ì¸í•„ìš”: {len(products) - stock_available - stock_out}ê°œ")
    
    # ê°€ê²© í†µê³„
    if products:
        avg_original = sum(p['original_price'] for p in products) / len(products)
        avg_sale = sum(p['sale_price'] for p in products) / len(products)
        avg_discount = sum(p['discount_rate'] for p in products if p['discount_rate'] > 0)
        discount_count = sum(1 for p in products if p['discount_rate'] > 0)
        
        print(f"\nğŸ’° ê°€ê²© ì •ë³´:")
        print(f"   í‰ê·  ì •ê°€: {avg_original:,.0f}ì›")
        print(f"   í‰ê·  íŒë§¤ê°€: {avg_sale:,.0f}ì›")
        if discount_count > 0:
            print(f"   í‰ê·  í• ì¸ìœ¨: {avg_discount/discount_count:.1f}%")
            print(f"   í• ì¸ ìƒí’ˆ: {discount_count}ê°œ")
    
    print("\n" + "="*80)
    print("âœ¨ AI ì‡¼í•‘ ì–´ì‹œìŠ¤í„´íŠ¸ê°€ ì´ ë°ì´í„°ë¥¼ ì°¸ì¡°í•˜ì—¬ ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
    print("="*80)


if __name__ == "__main__":
    main()

